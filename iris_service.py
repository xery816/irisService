# -*- coding: utf-8 -*-
"""
è™¹è†œè¯†åˆ« HTTP æœåŠ¡1
å¯åŠ¨å‘½ä»¤: python iris_service.py --host 0.0.0.0 --port 5000 --camera 0
"""

from flask import Flask, Response, jsonify, request
from flask_cors import CORS
import cv2
import threading
import time
import os
import shutil
import numpy as np

app = Flask(__name__)
CORS(app, origins="*")


class IrisService:
    def __init__(self):
        self.camera_index = 0  # å›ºå®šä½¿ç”¨ç´¢å¼• 0
        self.cap = None
        self.is_running = False
        self.current_frame = None
        self.is_iris_detected = False
        self.detection_result = {'detected': False}
        self.lock = threading.Lock()

    def start_camera(self):
        """å¯åŠ¨çº¢å¤–æ‘„åƒå¤´"""
        import time
        total_start = time.time()
        
        print(f"[1/3] æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´ {self.camera_index}...")
        step_start = time.time()
        
        if self.cap is None or not self.cap.isOpened():
            self.cap = cv2.VideoCapture(self.camera_index)
            step1_time = time.time() - step_start
            print(f"è€—æ—¶: {step1_time:.3f}ç§’")
            
            if not self.cap.isOpened():
                print(f"æ‘„åƒå¤´ {self.camera_index} æ‰“å¼€å¤±è´¥ï¼")
                return False
            
            # ä¸è®¾ç½®åˆ†è¾¨ç‡ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼Œé¿å…5ç§’å»¶è¿Ÿ
            # è¯»å–ä¸€å¸§æµ‹è¯•å¹¶è·å–é»˜è®¤åˆ†è¾¨ç‡
            print(f"[2/3] æµ‹è¯•è¯»å–ç¬¬ä¸€å¸§ï¼ˆä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡ï¼‰...")
            step_start = time.time()
            ret, test_frame = self.cap.read()
            step2_time = time.time() - step_start
            print(f"è€—æ—¶: {step2_time:.3f}ç§’")
            
            if ret:
                print(f"ç¬¬ä¸€å¸§è¯»å–æˆåŠŸï¼Œé»˜è®¤åˆ†è¾¨ç‡: {test_frame.shape}")
            else:
                print(f"ç¬¬ä¸€å¸§è¯»å–å¤±è´¥")
        
        print(f"[3/3] å¯åŠ¨é‡‡é›†çº¿ç¨‹...")
        step_start = time.time()
        self.is_running = True
        threading.Thread(target=self._capture_loop, daemon=True).start()
        step3_time = time.time() - step_start
        print(f"è€—æ—¶: {step3_time:.3f}ç§’")
        
        total_time = time.time() - total_start
        print(f"æ‘„åƒå¤´ {self.camera_index} å¯åŠ¨å®Œæˆ")
        print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
        return True

    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_running = False
        if self.cap:
            self.cap.release()
            self.cap = None
        print("æ‘„åƒå¤´å·²åœæ­¢")

    def _capture_loop(self):
        """æ‘„åƒå¤´é‡‡é›†å¾ªç¯"""
        frame_count = 0
        error_count = 0
        
        while self.is_running:
            if self.cap and self.cap.isOpened():
                ret, frame = self.cap.read()
                if ret:
                    frame_count += 1
                    if frame_count == 1:
                        print(f"é‡‡é›†çº¿ç¨‹ï¼šå·²é‡‡é›†ç¬¬ä¸€å¸§")
                    elif frame_count % 30 == 0:
                        print(f"é‡‡é›†çº¿ç¨‹ï¼šå·²é‡‡é›† {frame_count} å¸§")
                    
                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    with self.lock:
                        self.current_frame = gray
                    self._detect_iris(gray)
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                else:
                    error_count += 1
                    if error_count == 1:
                        print(f"é‡‡é›†çº¿ç¨‹ï¼šè¯»å–å¸§å¤±è´¥")
                    if error_count >= 10:
                        print(f"é‡‡é›†çº¿ç¨‹ï¼šè¿ç»­å¤±è´¥ {error_count} æ¬¡ï¼Œå¯èƒ½æ‘„åƒå¤´å¼‚å¸¸")
            else:
                print(f"é‡‡é›†çº¿ç¨‹ï¼šæ‘„åƒå¤´æœªæ‰“å¼€æˆ–å·²å…³é—­")
                break
            
            time.sleep(0.03)  # ~30fps
        
        print(f"é‡‡é›†çº¿ç¨‹å·²åœæ­¢ï¼Œå…±é‡‡é›† {frame_count} å¸§")

    def _detect_iris(self, frame):
        """è™¹è†œæ£€æµ‹"""
        try:
            from util.innerCircle import innerCircle
            from util.outerCircle import outerCircle

            inner = innerCircle(frame)
            outer = outerCircle(frame, inner)

            self.is_iris_detected = True
            self.detection_result = {
                'detected': True,
                'inner': inner.tolist(),
                'outer': outer.tolist()
            }
        except Exception:
            self.is_iris_detected = False
            self.detection_result = {'detected': False}

    def get_video_frame(self):
        """è·å–å¸¦æ£€æµ‹æ ‡è®°çš„è§†é¢‘å¸§"""
        with self.lock:
            if self.current_frame is None:
                return None
            frame = self.current_frame.copy()

        # ç»˜åˆ¶æ£€æµ‹åœ†
        if self.is_iris_detected and self.detection_result.get('detected'):
            from util.visualization import displayCircle
            inner = self.detection_result['inner']
            outer = self.detection_result['outer']
            frame = displayCircle(frame,
                                  inner[0], inner[1], inner[2],
                                  outer[0], outer[1], outer[2])
        return frame

    def capture_sample(self, user_id, eye):
        """é‡‡é›†ä¸€å¼ è™¹è†œæ ·æœ¬"""
        if not self.is_iris_detected:
            return {'success': False, 'error': 'æœªæ£€æµ‹åˆ°è™¹è†œ'}

        with self.lock:
            if self.current_frame is None:
                return {'success': False, 'error': 'æ— æ³•è·å–å›¾åƒ'}
            frame = self.current_frame.copy()

        # åˆ›å»ºç”¨æˆ·ç›®å½•
        user_dir = os.path.join('photo', user_id, eye)

        # ğŸ†• å¦‚æœæ˜¯è¯¥ç”¨æˆ·è¯¥çœ¼åˆ«çš„ç¬¬ä¸€å¼ ç…§ç‰‡ï¼ˆidx=1ï¼‰ï¼Œæ¸…ç©ºæ—§æ•°æ®
        if os.path.exists(user_dir):
            existing = [f for f in os.listdir(user_dir) if f.endswith('.jpeg')]
            if len(existing) == 0:
                # ç›®å½•å­˜åœ¨ä½†ä¸ºç©ºï¼Œè¯´æ˜æ˜¯æ–°çš„é‡‡é›†
                pass
            elif len(existing) > 0:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€æ¬¡é‡‡é›†æœ¬æ¬¡æ³¨å†Œï¼ˆé€šè¿‡æ£€æŸ¥ç´¢å¼•åˆ¤æ–­ï¼‰
                # å¦‚æœç›®å½•ä¸‹å·²æœ‰3å¼ ç…§ç‰‡ï¼Œè¯´æ˜ä¸Šæ¬¡æ³¨å†Œå®Œæˆäº†ï¼Œè¿™æ¬¡æ˜¯é‡æ–°æ³¨å†Œ
                if len(existing) >= 3:
                    print(f"[æ¸…ç†æ—§æ•°æ®] åˆ é™¤ {user_id}/{eye} çš„æ—§ç…§ç‰‡ï¼š{len(existing)} å¼ ")
                    shutil.rmtree(user_dir)

        os.makedirs(user_dir, exist_ok=True)

        # è®¡ç®—å½“å‰ç´¢å¼•
        existing = len([f for f in os.listdir(user_dir) if f.endswith('.jpeg')])
        idx = existing + 1
        timestamp = int(time.time())
        filename = f'{timestamp}_{eye}_{idx}.jpeg'
        photo_path = os.path.join(user_dir, filename)

        # ä¿å­˜å›¾åƒ
        cv2.imwrite(photo_path, frame)

        if not os.path.exists(photo_path):
            return {'success': False, 'error': 'ä¿å­˜å¤±è´¥'}

        print(f"é‡‡é›†æˆåŠŸ: {photo_path}")
        return {
            'success': True,
            'path': photo_path,
            'eye': eye,
            'index': idx
        }

    def generate_features(self, user_id=None):
        """ç”Ÿæˆç‰¹å¾æ•°æ®é›†"""
        try:
            # ğŸ†• å¦‚æœæŒ‡å®šäº† user_idï¼Œå…ˆåˆ é™¤è¯¥ç”¨æˆ·çš„æ—§ç‰¹å¾
            if user_id:
                feature_user_dir = os.path.join('feature', user_id)
                if os.path.exists(feature_user_dir):
                    print(f"[æ¸…ç†æ—§ç‰¹å¾] åˆ é™¤ {user_id} çš„æ—§ç‰¹å¾æ•°æ®")
                    shutil.rmtree(feature_user_dir)

            from util.feature import generateFeatureDataset
            print("å¼€å§‹ç”Ÿæˆç‰¹å¾æ•°æ®é›†...")
            generateFeatureDataset()
            print("ç‰¹å¾æ•°æ®é›†ç”Ÿæˆå®Œæˆ")
            return {'success': True}
        except Exception as e:
            print(f"ç‰¹å¾ç”Ÿæˆå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}

    def recognize(self):
        """è™¹è†œè¯†åˆ«"""
        if not self.is_iris_detected:
            return {'success': False, 'error': 'æœªæ£€æµ‹åˆ°è™¹è†œ'}

        with self.lock:
            if self.current_frame is None:
                return {'success': False, 'error': 'æ— æ³•è·å–å›¾åƒ'}
            frame = self.current_frame.copy()

        try:
            from util.contrast import contrast
            name, eye, scores = contrast(frame)

            if name and scores:
                best_score = scores[0][1]
                confidence = max(0, 100 - (best_score / 1000))
                print(f"è¯†åˆ«æˆåŠŸ: {name}, çœ¼åˆ«: {eye}, ç½®ä¿¡åº¦: {confidence:.2f}%")
                return {
                    'success': True,
                    'user_id': name,
                    'eye': eye,
                    'confidence': round(confidence, 2),
                    'score': best_score
                }

            return {'success': False, 'error': 'æœªæ‰¾åˆ°åŒ¹é…'}
        except Exception as e:
            print(f"è¯†åˆ«å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}


# å…¨å±€æœåŠ¡å®ä¾‹
iris_service = IrisService()


# ==================== HTTP API ====================

@app.route('/api/status', methods=['GET'])
def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return jsonify({
        'service_running': True,
        'camera_running': iris_service.is_running,
        'camera_index': 0  # å›ºå®šè¿”å› 0
    })


@app.route('/api/camera/list', methods=['GET'])
def list_cameras():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ‘„åƒå¤´"""
    cameras = []
    debug_info = []  # è°ƒè¯•ä¿¡æ¯

    # 1. è·å–æ‰€æœ‰ /dev/video* è®¾å¤‡è·¯å¾„ï¼ˆä½¿ç”¨ globï¼Œæ›´å¯é ï¼‰
    import glob
    device_paths = {}
    try:
        video_devices = glob.glob('/dev/video*')
        for device_path in video_devices:
            # ä»è·¯å¾„ä¸­æå–ç´¢å¼•å·ï¼Œä¾‹å¦‚ /dev/video0 -> 0
            device_name = device_path.split('/')[-1]  # video0
            if device_name[5:].isdigit():  # ç¡®ä¿ video åé¢æ˜¯æ•°å­—
                idx = int(device_name.replace('video', ''))
                device_paths[idx] = device_path
    except Exception as e:
        print(f"[æ‘„åƒå¤´åˆ—è¡¨] è¯»å– /dev/video* è®¾å¤‡å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)})

    print(f"[æ‘„åƒå¤´åˆ—è¡¨] å‘ç° {len(device_paths)} ä¸ªè®¾å¤‡èŠ‚ç‚¹: {list(device_paths.values())}")

    # ä¸´æ—¶æŠ‘åˆ¶ OpenCV è­¦å‘Šæ—¥å¿—
    import os
    original_log_level = os.environ.get('OPENCV_LOG_LEVEL')
    os.environ['OPENCV_LOG_LEVEL'] = 'FATAL'  # åªæ˜¾ç¤ºè‡´å‘½é”™è¯¯

    try:
        # 2. ä½¿ç”¨ OpenCV æµ‹è¯•å“ªäº›ç´¢å¼•å¯ç”¨
        for idx in sorted(device_paths.keys()):
            device_path = device_paths[idx]
            debug_entry = {
                'index': idx,
                'device': device_path,
                'opencv_opened': False,
                'error': None,
                'device_caps': None
            }

            try:
                # å…ˆæ£€æŸ¥è®¾å¤‡èƒ½åŠ›
                try:
                    import subprocess
                    result = subprocess.run(
                        ['v4l2-ctl', '--device', device_path, '--all'],
                        capture_output=True,
                        text=True,
                        timeout=1
                    )

                    if result.returncode == 0:
                        # æå–è®¾å¤‡èƒ½åŠ›
                        for line in result.stdout.split('\n'):
                            if 'Device Caps' in line:
                                debug_entry['device_caps'] = line.strip()
                            if 'Card type' in line:
                                debug_entry['card_type'] = line.split(':', 1)[1].strip()
                except Exception as e:
                    debug_entry['v4l2_error'] = str(e)

                # å°è¯•ç”¨ OpenCV æ‰“å¼€
                cap = cv2.VideoCapture(idx)

                if cap.isOpened():
                    debug_entry['opencv_opened'] = True

                    # è·å– OpenCV èƒ½æä¾›çš„ä¿¡æ¯
                    camera_info = {
                        'index': idx,
                        'device': device_path,
                        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                        'fps': cap.get(cv2.CAP_PROP_FPS),
                        'name': debug_entry.get('card_type', f'Camera {idx}')
                    }

                    cameras.append(camera_info)
                    cap.release()
                    print(f"[æ‘„åƒå¤´åˆ—è¡¨] âœ“ {device_path} å¯ç”¨: {camera_info['name']}")
                else:
                    debug_entry['error'] = 'OpenCV failed to open (å¯èƒ½æ˜¯å…ƒæ•°æ®è®¾å¤‡)'
                    print(f"[æ‘„åƒå¤´åˆ—è¡¨] âœ— {device_path} æ— æ³•æ‰“å¼€ (å¯èƒ½æ˜¯å…ƒæ•°æ®è®¾å¤‡)")

            except Exception as e:
                debug_entry['error'] = str(e)
                print(f"[æ‘„åƒå¤´åˆ—è¡¨] âœ— {device_path} å¼‚å¸¸: {e}")

            debug_info.append(debug_entry)

    finally:
        # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
        if original_log_level is not None:
            os.environ['OPENCV_LOG_LEVEL'] = original_log_level
        else:
            os.environ.pop('OPENCV_LOG_LEVEL', None)

    return jsonify({
        'success': True,
        'cameras': cameras,
        'debug': debug_info  # è¿”å›è°ƒè¯•ä¿¡æ¯
    })


@app.route('/api/camera/set-device', methods=['POST'])
def set_camera_device():
    """è®¾ç½®æ‘„åƒå¤´è®¾å¤‡ï¼ˆæ”¯æŒ /dev/videoX æˆ–ç´¢å¼•å·ï¼‰"""
    data = request.json or {}
    device = data.get('device')

    if not device:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘ device å‚æ•°'})

    # è§£æè®¾å¤‡è·¯å¾„æˆ–ç´¢å¼•
    if isinstance(device, str) and device.startswith('/dev/video'):
        # å¦‚æœæ˜¯è®¾å¤‡è·¯å¾„ï¼Œæå–ç´¢å¼•å·
        try:
            index = int(device.replace('/dev/video', ''))
        except ValueError:
            return jsonify({'success': False, 'error': f'æ— æ•ˆçš„è®¾å¤‡è·¯å¾„: {device}'})
    elif isinstance(device, (int, str)):
        # å¦‚æœæ˜¯ç´¢å¼•å·
        try:
            index = int(device)
        except ValueError:
            return jsonify({'success': False, 'error': 'device å¿…é¡»æ˜¯æ•°å­—æˆ– /dev/videoX æ ¼å¼'})
    else:
        return jsonify({'success': False, 'error': 'device æ ¼å¼é”™è¯¯'})

    if index < 0:
        return jsonify({'success': False, 'error': 'ç´¢å¼•å¿…é¡»å¤§äºç­‰äº0'})

    # éªŒè¯è®¾å¤‡æ˜¯å¦å­˜åœ¨
    device_path = f'/dev/video{index}'
    if not os.path.exists(device_path):
        return jsonify({'success': False, 'error': f'è®¾å¤‡ {device_path} ä¸å­˜åœ¨'})

    # å¦‚æœæ‘„åƒå¤´æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å†åˆ‡æ¢
    was_running = iris_service.is_running
    if was_running:
        print(f"[è®¾ç½®è®¾å¤‡] åœæ­¢å½“å‰æ‘„åƒå¤´ (ç´¢å¼• {iris_service.camera_index})")
        iris_service.stop_camera()

    # è®¾ç½®æ–°ç´¢å¼•
    iris_service.camera_index = index
    print(f"[è®¾ç½®è®¾å¤‡] æ‘„åƒå¤´å·²è®¾ç½®ä¸º {device_path} (ç´¢å¼• {index})")

    # å¦‚æœä¹‹å‰åœ¨è¿è¡Œï¼Œé‡æ–°å¯åŠ¨
    if was_running:
        print(f"[è®¾ç½®è®¾å¤‡] é‡æ–°å¯åŠ¨æ‘„åƒå¤´ {device_path}")
        iris_service.start_camera()
        return jsonify({
            'success': True,
            'message': f'æ‘„åƒå¤´å·²è®¾ç½®ä¸º {device_path} å¹¶é‡æ–°å¯åŠ¨',
            'device': device_path,
            'index': index
        })

    return jsonify({
        'success': True,
        'message': f'æ‘„åƒå¤´å·²è®¾ç½®ä¸º {device_path}',
        'device': device_path,
        'index': index
    })


@app.route('/api/camera/start', methods=['POST'])
def start_camera():
    """å¯åŠ¨æ‘„åƒå¤´"""
    if iris_service.is_running:
        return jsonify({'success': False, 'error': 'æ‘„åƒå¤´å·²åœ¨è¿è¡Œ'})

    try:
        iris_service.start_camera()
        return jsonify({'success': True, 'message': 'æ‘„åƒå¤´å·²å¯åŠ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/camera/stop', methods=['POST'])
def stop_camera_api():
    """åœæ­¢æ‘„åƒå¤´"""
    if not iris_service.is_running:
        return jsonify({'success': False, 'error': 'æ‘„åƒå¤´æœªè¿è¡Œ'})
    
    try:
        iris_service.stop_camera()
        return jsonify({'success': True, 'message': 'æ‘„åƒå¤´å·²åœæ­¢'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/video/stream')
def video_stream():
    """MJPEG è§†é¢‘æµ - å¼‚æ­¥å¯åŠ¨æ‘„åƒå¤´"""
    # å¼‚æ­¥å¯åŠ¨æ‘„åƒå¤´ï¼Œä¸é˜»å¡HTTPå“åº”
    if not iris_service.is_running:
        print("[è§†é¢‘æµ] å¼‚æ­¥å¯åŠ¨æ‘„åƒå¤´...")
        threading.Thread(target=iris_service.start_camera, daemon=True).start()
    
    def generate():
        # ç­‰å¾…æ‘„åƒå¤´å¯åŠ¨å¹¶é‡‡é›†åˆ°ç¬¬ä¸€å¸§
        timeout = 10  # 10ç§’è¶…æ—¶
        start_time = time.time()
        
        while iris_service.get_video_frame() is None:
            elapsed = time.time() - start_time
            if elapsed > timeout:
                # è¶…æ—¶ï¼Œè¿”å›é”™è¯¯æç¤º
                error_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(error_frame, 'Camera Timeout', (150, 240),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
                _, buffer = cv2.imencode('.jpg', error_frame)
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
                return
            
            # æ˜¾ç¤ºåŠ è½½ä¸­æç¤º
            loading_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            loading_text = f'Loading... {int(elapsed)}s'
            cv2.putText(loading_frame, loading_text, (180, 240),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
            _, buffer = cv2.imencode('.jpg', loading_frame)
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            time.sleep(0.3)  # æ¯0.3ç§’æ›´æ–°ä¸€æ¬¡
        
        # æ‘„åƒå¤´å·²å°±ç»ªï¼Œå¼€å§‹æ¨é€çœŸå®è§†é¢‘æµ
        print("[è§†é¢‘æµ] æ‘„åƒå¤´å·²å°±ç»ªï¼Œå¼€å§‹æ¨é€è§†é¢‘")
        while True:
            frame = iris_service.get_video_frame()
            if frame is not None:
                # ç¡®ä¿æ˜¯ BGR æ ¼å¼ç”¨äºç¼–ç 
                if len(frame.shape) == 2:
                    frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
                _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            time.sleep(0.033)  # ~30fps

    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/api/register/capture', methods=['POST'])
def capture_iris():
    """é‡‡é›†è™¹è†œæ ·æœ¬"""
    data = request.json or {}
    user_id = data.get('user_id')
    eye = data.get('eye', 'L')

    if not user_id:
        return jsonify({'success': False, 'error': 'ç¼ºå°‘ user_id'})
    if eye not in ('L', 'R'):
        return jsonify({'success': False, 'error': 'eye å¿…é¡»æ˜¯ L æˆ– R'})

    result = iris_service.capture_sample(user_id, eye)
    return jsonify(result)


@app.route('/api/register/complete', methods=['POST'])
def complete_registration():
    """å®Œæˆæ³¨å†Œï¼Œç”Ÿæˆç‰¹å¾ - å®Œæˆåè‡ªåŠ¨å…³é—­æ‘„åƒå¤´"""
    data = request.json or {}
    user_id = data.get('user_id')
    result = iris_service.generate_features(user_id)
    
    # æ³¨å†Œå®Œæˆåè‡ªåŠ¨å…³é—­æ‘„åƒå¤´
    if iris_service.is_running:
        print("[æ³¨å†Œå®Œæˆ] è‡ªåŠ¨å…³é—­æ‘„åƒå¤´...")
        iris_service.stop_camera()
    
    return jsonify(result)


@app.route('/api/recognize', methods=['POST'])
def recognize_iris():
    """è™¹è†œè¯†åˆ« - è‡ªåŠ¨å¯åŠ¨å’Œå…³é—­æ‘„åƒå¤´"""
    # è¯†åˆ«å‰è‡ªåŠ¨å¯åŠ¨æ‘„åƒå¤´
    camera_was_running = iris_service.is_running
    if not camera_was_running:
        print("[è™¹è†œè¯†åˆ«] è‡ªåŠ¨å¯åŠ¨æ‘„åƒå¤´...")
        iris_service.start_camera()
        time.sleep(0.5)  # ç­‰å¾…æ‘„åƒå¤´å¯åŠ¨å¹¶é‡‡é›†ç¬¬ä¸€å¸§
    
    # æ‰§è¡Œè¯†åˆ«
    result = iris_service.recognize()
    
    # å¦‚æœæ˜¯ä¸´æ—¶å¯åŠ¨çš„ï¼Œè¯†åˆ«åè‡ªåŠ¨å…³é—­
    if not camera_was_running:
        print("[è™¹è†œè¯†åˆ«] è‡ªåŠ¨å…³é—­æ‘„åƒå¤´...")
        iris_service.stop_camera()
    
    return jsonify(result)


# ==================== å¯åŠ¨ ====================

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='è™¹è†œè¯†åˆ«æœåŠ¡')
    parser.add_argument('--host', default='0.0.0.0', help='ç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=5000, help='ç›‘å¬ç«¯å£ (é»˜è®¤: 5000)')
    args = parser.parse_args()

    # æ‘„åƒå¤´ç´¢å¼•å›ºå®šä¸º 0
    print("=" * 50)
    print(f"è™¹è†œè¯†åˆ«æœåŠ¡å¯åŠ¨")
    print(f"åœ°å€: http://{args.host}:{args.port}")
    print(f"æ‘„åƒå¤´ç´¢å¼•: 0 (æœªå¯åŠ¨)")
    print("")
    print("API ç«¯ç‚¹:")
    print(f"  - çŠ¶æ€æŸ¥è¯¢: http://{args.host}:{args.port}/api/status")
    print(f"  - å¯åŠ¨æ‘„åƒå¤´: POST http://{args.host}:{args.port}/api/camera/start")
    print(f"  - åœæ­¢æ‘„åƒå¤´: POST http://{args.host}:{args.port}/api/camera/stop")
    print(f"  - è§†é¢‘æµ: http://{args.host}:{args.port}/api/video/stream")
    print("")
    print("æç¤º: æ‘„åƒå¤´éœ€è¦æ‰‹åŠ¨å¯åŠ¨åæ‰èƒ½ä½¿ç”¨")
    print("=" * 50)

    app.run(host=args.host, port=args.port, threaded=True)

